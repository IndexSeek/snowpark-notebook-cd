{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Generate store information with empty hourly traffic for the next four weeks for forecasting. \n",
    "\n",
    "This notebook is continuing using the example described in [Building and deploying a time series forecast with Hex + Snowflake](https://quickstarts.snowflake.com/guide/hex/index.html#0). This entire example higlights how we can use Snowflake to perform parallel hyperparameter tuning forecasting foot traffic. Please take a look at Chase Romano's article [Parallel Hyperparameter tuning using Snowpark](https://medium.com/snowflake/parallel-hyperparameter-tuning-using-snowpark-53cdec2faf77) for more information.\n",
    "\n",
    "We will begin by establishing our Snowflake connection and Snowpark session. This demo assumes the user has access to the `SYSADMIN` role and a virtual warehouse named `COMPUTE_WH` exists and is available for usage. \n",
    "\n",
    "We're assuming the tables `CALENDAR_INFO` and `HOURLY_TRAFFIC` have already been created and populated with data based on the [1-data-ingestion.ipynb](1-data-ingestion.ipynb) notebook in this repository."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from snowflake.snowpark import Session\n",
    "from snowflake.snowpark.types import DateType, StringType\n",
    "from snowflake.snowpark.functions import (\n",
    "    cast,\n",
    "    col,\n",
    "    current_date,\n",
    "    to_timestamp,\n",
    "    lit,\n",
    "    dateadd,\n",
    "    hour,\n",
    "    to_date,\n",
    ")\n",
    "import pandas as pd\n",
    "import os\n",
    "\n",
    "connection_params = {\n",
    "    \"account\": os.environ.get(\"SNOWFLAKE_ACCOUNT\"),\n",
    "    \"user\": os.environ.get(\"SNOWFLAKE_USER\"),\n",
    "    \"password\": os.environ.get(\"SNOWFLAKE_PASSWORD\"),\n",
    "    \"database\": os.environ.get(\"SNOWFLAKE_DATABASE\"),\n",
    "    \"schema\": os.environ.get(\"SNOWFLAKE_SCHEMA\"),\n",
    "    \"role\": \"SYSADMIN\",\n",
    "    \"warehouse\": \"COMPUTE_WH\",\n",
    "}\n",
    "\n",
    "session = Session.builder.configs(connection_params).create()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create a DataFrame with relevant historical data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "store_hourly_info_df = session.table(\"HOURLY_TRAFFIC\")\n",
    "store_calendar_info_df = session.table(\"CALENDAR_INFO\")\n",
    "\n",
    "# Extract date and hour from the time stamp in Hourly traffic\n",
    "past = store_hourly_info_df.select(\n",
    "    \"TIME_POINTS\",\n",
    "    col(\"TIME_POINTS\").cast(DateType()).alias(\"DATE\"),\n",
    "    hour(col(\"TIME_POINTS\")).alias(\"HOUR\"),\n",
    "    \"STORE_ID\",\n",
    "    \"COLLEGE_TOWN\",\n",
    "    \"HOURLY_TRAFFIC\",\n",
    ")\n",
    "\n",
    "# Join the Calendar info table to the Hourly traffic table\n",
    "# Filter hour between 7 and 22 since the restaraunts are only open from 7am -> 10pm\n",
    "past_final = (\n",
    "    past.join(\n",
    "        store_calendar_info_df,\n",
    "        (store_calendar_info_df.col(\"CALENDAR_DATE\") == past.col(\"DATE\")),\n",
    "        \"left\",\n",
    "    )\n",
    "    .select(\n",
    "        col(\"TIME_POINTS\"),\n",
    "        col(\"HOUR\"),\n",
    "        \"STORE_ID\",\n",
    "        \"COLLEGE_TOWN\",\n",
    "        \"CALENDAR_WEEK_DAY_NBR\",\n",
    "        \"CALENDAR_MTH_DAY_NBR\",\n",
    "        \"CALENDAR_MTH\",\n",
    "        \"CALENDAR_YEAR\",\n",
    "        \"HOLIDAY_NAME\",\n",
    "        \"HOURLY_TRAFFIC\",\n",
    "    )\n",
    "    .filter(col(\"HOUR\").between(7, 22))\n",
    "    .na.fill({\"HOLIDAY_NAME\": \"No Holiday\"})\n",
    ")\n",
    "\n",
    "past_final.limit(10).toPandas()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create a column that has the next 672 hours (28 days) in datetime format."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_date = session.range(672).select(dateadd(\"HOUR\", \"ID\", current_date()).as_(\"DATE\"))\n",
    "\n",
    "df_date = df_date.with_column(\"HOUR\", hour(df_date[\"DATE\"]))\n",
    "\n",
    "df_date = df_date.select(to_date(df_date[\"DATE\"]).as_(\"DATE\"), \"HOUR\").filter(\n",
    "    col(\"HOUR\").between(7, 22)\n",
    ")\n",
    "\n",
    "# Cross join to make sure each store gets a value for the next 4 weeks\n",
    "df_store = (\n",
    "    session.table(\"HOURLY_TRAFFIC\")\n",
    "    .select(\n",
    "        col(\"STORE_ID\").cast(\"string\").alias(\"STORE_ID\"),\n",
    "        col(\"COLLEGE_TOWN\").cast(\"string\").alias(\"COLLEGE_TOWN\"),\n",
    "    )\n",
    "    .distinct()\n",
    ")\n",
    "stores = df_date.cross_join(df_store)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Add in Calendar Information to create the final future table."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "future_cal = (\n",
    "    session.table(\"CALENDAR_INFO\")\n",
    "    .select(\n",
    "        \"CALENDAR_DATE\",\n",
    "        \"CALENDAR_WEEK_DAY_NBR\",\n",
    "        \"CALENDAR_MTH_DAY_NBR\",\n",
    "        \"CALENDAR_MTH\",\n",
    "        \"CALENDAR_YEAR\",\n",
    "        \"HOLIDAY_NAME\",\n",
    "    )\n",
    "    .filter(\n",
    "        (col(\"CALENDAR_DATE\") >= current_date())\n",
    "        & (col(\"CALENDAR_DATE\") <= current_date() + 28)\n",
    "    )\n",
    ")\n",
    "\n",
    "future_cal = future_cal.na.fill({\"HOLIDAY_NAME\": \"No Holiday\"})\n",
    "\n",
    "# Join store info and calendar data\n",
    "future_df = stores.join(\n",
    "    future_cal, stores.col(\"DATE\") == future_cal.col(\"CALENDAR_DATE\"), \"right\"\n",
    ")\n",
    "future_df = future_df.drop(\"CALENDAR_DATE\")\n",
    "\n",
    "future_df = future_df.withColumn(\n",
    "    \"DATE_HOUR\", to_timestamp(dateadd(\"hour\", col(\"HOUR\"), col(\"DATE\")))\n",
    ")\n",
    "future_df = future_df.drop(\"DATE\")\n",
    "\n",
    "future_df = future_df.withColumn(\"HOURLY_TRAFFIC\", lit(0))\n",
    "\n",
    "future_df = future_df.select(\n",
    "    \"DATE_HOUR\",\n",
    "    \"HOUR\",\n",
    "    \"STORE_ID\",\n",
    "    \"COLLEGE_TOWN\",\n",
    "    \"CALENDAR_WEEK_DAY_NBR\",\n",
    "    \"CALENDAR_MTH_DAY_NBR\",\n",
    "    \"CALENDAR_MTH\",\n",
    "    \"CALENDAR_YEAR\",\n",
    "    \"HOLIDAY_NAME\",\n",
    "    \"HOURLY_TRAFFIC\",\n",
    ")\n",
    "\n",
    "future_df.limit(5).toPandas()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Union the historical and future tables together and write the final features table to Snowflake."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "union_df = past_final.union(future_df).select(\n",
    "    \"TIME_POINTS\",\n",
    "    \"HOUR\",\n",
    "    cast(\"STORE_ID\", StringType()).alias(\"STORE_ID\"),\n",
    "    \"COLLEGE_TOWN\",\n",
    "    \"CALENDAR_WEEK_DAY_NBR\",\n",
    "    \"CALENDAR_MTH_DAY_NBR\",\n",
    "    \"CALENDAR_MTH\",\n",
    "    \"CALENDAR_YEAR\",\n",
    "    \"HOLIDAY_NAME\",\n",
    "    \"HOURLY_TRAFFIC\",\n",
    ")\n",
    "\n",
    "union_df.write.save_as_table(\"MODEL_FEATURES\", mode=\"overwrite\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.0 (tags/v3.8.0:fa919fd, Oct 14 2019, 19:37:50) [MSC v.1916 64 bit (AMD64)]"
  },
  "vscode": {
   "interpreter": {
    "hash": "2054dec0498b5c123877e19b450b0c397daa43145025323e8362f09b588247ab"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
